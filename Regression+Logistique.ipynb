{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BUCKET = 'cpb100-200708.appspot.com'\n",
    "PROJECT = 'cpb100'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import google.datalab as datalab\n",
    "import google.datalab.ml as ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "train_x = pd.read_csv('train_preprocessed.csv').fillna(\" \")\n",
    "test_x = pd.read_csv('test_preprocessed.csv').fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train_x['comment_text']\n",
    "test_text = test_x['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=30000)\n",
    "\n",
    "\n",
    "word_vectorizer.fit(all_text)\n",
    "train_features = word_vectorizer.transform(train_text)\n",
    "test_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9548277978230575\n",
      "CV score for class severe_toxic is 0.9826409307079059\n",
      "CV score for class obscene is 0.9726766421702265\n",
      "CV score for class threat is 0.9765599064070264\n",
      "CV score for class insult is 0.9668623185208057\n",
      "CV score for class identity_hate is 0.9582955822617715\n",
      "Total CV score is 0.968643862981799\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(C=0.10, solver='sag', penalty='l2', random_state=0)\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=5, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {'C':[0.1, 1., 10., 100.], 'penalty':['l1', 'l2']}\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1.0, 10.0, 100.0], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "#for class_name in class_names:\n",
    "train_target = train[class_name]\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "\n",
    "clf = GridSearchCV(classifier, params, cv=2)\n",
    "clf.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached fasttext-0.8.3.tar.gz\n",
      "Requirement already satisfied: numpy>=1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from fasttext)\n",
      "Requirement already satisfied: future in /usr/local/envs/py3env/lib/python3.5/site-packages (from fasttext)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Running setup.py bdist_wheel for fasttext ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/55/0a/95/e23f773666d3487ee7456b220f7e8d37e99b74833b20dd06a0\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.8.3\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_x.columns = ['id', 'comment_text', '__label__toxic', '__label__severe_toxic', '__label__obscene', \n",
    "                 '__label__threat', '__label__insult', '__label__identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data_column = ['comment_text', '__label__toxic', '__label__severe_toxic', '__label__obscene', \n",
    "                 '__label__threat', '__label__insult', '__label__identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data = train_x[train_data_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>__label__toxic</th>\n",
       "      <th>__label__severe_toxic</th>\n",
       "      <th>__label__obscene</th>\n",
       "      <th>__label__threat</th>\n",
       "      <th>__label__insult</th>\n",
       "      <th>__label__identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  __label__toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...               0   \n",
       "1  D'aww! He matches this background colour I'm s...               0   \n",
       "2  Hey man, I'm really not trying to edit war. It...               0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...               0   \n",
       "4  You, sir, are my hero. Any chance you remember...               0   \n",
       "\n",
       "   __label__severe_toxic  __label__obscene  __label__threat  __label__insult  \\\n",
       "0                      0                 0                0                0   \n",
       "1                      0                 0                0                0   \n",
       "2                      0                 0                0                0   \n",
       "3                      0                 0                0                0   \n",
       "4                      0                 0                0                0   \n",
       "\n",
       "   __label__identity_hate  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_data = test_x['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fmt='%s, %d, %d, %d, %d, %d, %d'\n",
    "np.savetxt('train.txt', train_data.values, fmt=fmt, delimiter=\"\\t\", header=\"comment_text\\t__label__toxic\\t__label__severe_toxic\\t__label__obscene\\t__label__threat\\t__label__insult\\t__label__identity_hat\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('test.txt', test_data.values, fmt='%s', delimiter=\"\\t\", header=\"comment_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifier = fasttext.supervised('train.txt', 'model', label_prefix='__label__', lr=0.1, loss=\"softmax\", epoch=5, thread=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = classifier.test('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)],\n",
       " [('obscene', 0.166016),\n",
       "  ('insult', 0.166016),\n",
       "  ('severe_toxic', 0.166016),\n",
       "  ('toxic', 0.166016),\n",
       "  ('threat', 0.166016),\n",
       "  ('identity_hat', 0.166016)]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba('test.txt', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)],\n",
       " [('toxic', 0.166016)]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
